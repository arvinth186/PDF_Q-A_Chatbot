<h1 align="center">ğŸ“˜ PDF Q&A Chatbot (LangChain + Groq + HuggingFace + Streamlit)</h1>

<p align="center">
An <b>AI-powered PDF Question-Answering Chatbot</b> built with <b>LangChain</b>, <b>Groq Llama 3</b>, and <b>HuggingFace Embeddings</b> â€” all inside an interactive <b>Streamlit</b> interface.<br>
Upload any PDF, ask a question, and get detailed answers with a <b>ChatGPT-like typing effect</b>.
</p>

---

<h2>ğŸš€ Features</h2>

<ul>
  <li>ğŸ“‚ <b>Upload Any PDF</b> â€“ Instantly process any document you upload.</li>
  <li>ğŸ” <b>RAG-Based Q&A</b> â€“ Retrieval-Augmented Generation ensures answers come <i>only</i> from your PDF.</li>
  <li>ğŸ§  <b>Detailed Explanations</b> â€“ Provides structured, multi-paragraph responses.</li>
  <li>âŒ¨ï¸ <b>ChatGPT-Style Typing Animation</b> â€“ Simulated real-time typing effect.</li>
  <li>âš¡ <b>Fast Vector Search</b> â€“ FAISS handles rapid context retrieval.</li>
  <li>ğŸ¨ <b>Clean Streamlit UI</b> â€“ Simple, modern, deployable anywhere.</li>
</ul>

---

<h2>ğŸ§  How It Works</h2>

<ol>
  <li><b>Upload a PDF</b> â†’ The app reads your file using <code>PyPDFLoader</code>.</li>
  <li><b>Chunking & Embeddings</b> â†’ The file is split into smaller chunks using <code>RecursiveCharacterTextSplitter</code> and embedded via <b>HuggingFace Embeddings</b>.</li>
  <li><b>Vector Store</b> â†’ All chunks are stored in a <b>FAISS</b> vector database.</li>
  <li><b>Ask a Question</b> â†’ Your query is compared with document chunks to retrieve relevant context.</li>
  <li><b>Groq LLM Response</b> â†’ The context + query is sent to <b>Llama-3.1-8B-Instant</b> for a structured, contextual answer.</li>
</ol>

---

<h2>ğŸ§© Tech Stack</h2>

<table>
<tr><th>Component</th><th>Library / Tool</th></tr>
<tr><td>Frontend</td><td>Streamlit</td></tr>
<tr><td>LLM Backend</td><td>Groq Llama-3.1-8B-Instant</td></tr>
<tr><td>Vector Store</td><td>FAISS</td></tr>
<tr><td>Embeddings</td><td>HuggingFace Embeddings</td></tr>
<tr><td>Document Loader</td><td>LangChain PyPDFLoader</td></tr>
<tr><td>Framework</td><td>LangChain (Classic + Community Modules)</td></tr>
</table>

---

<h2>ğŸ› ï¸ Installation</h2>

<h3>1ï¸âƒ£ Clone the Repository</h3>

```bash
git clone https://github.com/yourusername/pdf-qa-chatbot.git
cd pdf-qa-chatbot
```

<h3>2ï¸âƒ£ Create a Virtual Environment</h3>

```bash
conda create -n pdf_qa python=3.10 -y
conda activate pdf_qa
```

<h3>3ï¸âƒ£ Install Dependencies</h3>

Create a <b>requirements.txt</b> file with:
```txt
streamlit
langchain
langchain_groq
langchain_huggingface
langchain_community
faiss-cpu
python-dotenv
PyPDF2
```

Then run:

```bash
pip install -r requirements.txt
```

<h3>4ï¸âƒ£ Setup Environment Variables</h3>

Create a file named <b>.env</b> in your root directory:
```env
GROQ_API_KEY=your_groq_api_key_here
HF_TOKEN=your_huggingface_token_here
```

ğŸ‘‰ Get your keys from:

<ul> <li><a href="https://console.groq.com/keys">Groq Cloud API Key</a></li> <li><a href="https://huggingface.co/settings/tokens">HuggingFace Access Token</a></li> </ul>

<h2>â–¶ï¸ Run the App</h2>

```bash
streamlit run app2.py
```

Then open: <a href="http://localhost:8501">http://localhost:8501
</a>

<h2>ğŸ’¡ Usage</h2> <ol> <li>Click <b>ğŸ“¤ Upload your PDF</b> and select a document.</li> <li>Wait while embeddings are generated.</li> <li>Ask a question such as: <ul> <li>â€œSummarize the introduction section.â€</li> <li>â€œWhat methods were used in this research?â€</li> <li>â€œWhat are the main findings?â€</li> </ul> </li> <li>The chatbot responds with a detailed, animated answer.</li> <li>Expand <b>ğŸ“š Retrieved Context</b> to view the exact document snippets used.</li> </ol>

<h2>ğŸ“¦ Folder Structure</h2>

```bash
ğŸ“¦ pdf-qa-chatbot
â”œâ”€â”€ app2.py                # Main Streamlit app
â”œâ”€â”€ .env                   # API keys (ignored by git)
â”œâ”€â”€ requirements.txt        # Dependencies
â”œâ”€â”€ README.md               # Documentation
â””â”€â”€ temp_uploaded.pdf       # Temporary uploaded file
```

<h2>âœ¨ Example Output</h2> <blockquote> <b>User:</b> Explain the main conclusion of the paper.<br><br> <b>ğŸ¤– Chatbot:</b> The paper concludes that neural network optimization improves model accuracy through adaptive gradient methods like Adam and RMSprop. These methods effectively balance convergence and generalization, resulting in superior performance across various datasets.â–Œ </blockquote>

---

<h2>ğŸ“· Dashboard Preview</h2>

<p align="center">
  <img src="Dashboard_preview.png" alt="PDF Q&A Chatbot Preview" width="800">
</p>

<p align="center">
  <i>Example interface of the Streamlit-based PDF Q&A Chatbot.</i>
</p>

---


<h2>ğŸ§­ Future Improvements</h2> <ul> <li>ğŸ§  Add chat memory for multi-turn conversations.</li> <li>ğŸ“š Support multiple PDF uploads.</li> <li>ğŸ’¾ Persistent FAISS vector caching.</li> <li>ğŸŒ Deploy on Streamlit Cloud or Hugging Face Spaces.</li> <li>ğŸ¤ Add voice input and text-to-speech support.</li> </ul>

<h2>ğŸ’– Acknowledgements</h2> <p>Special thanks to:</p> <ul> <li><a href="https://www.langchain.com/">LangChain</a> â€“ modular AI orchestration</li> <li><a href="https://groq.com/">Groq Cloud</a> â€“ ultra-fast inference engine</li> <li><a href="https://huggingface.co/">HuggingFace</a> â€“ embedding models</li> <li><a href="https://streamlit.io/">Streamlit</a> â€“ easy interactive app building</li> </ul>

<h2>ğŸ‘¨â€ğŸ’» Author</h2> <p><b>Arvinth Athikesav</b><br> ğŸš€ Passionate about Generative AI, LangChain, and LLM Applications.<br> ğŸ“« Connect on <a href="https://github.com/arvinth186">GitHub</a> </p> 


